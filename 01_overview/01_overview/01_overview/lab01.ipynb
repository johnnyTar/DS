{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01\n",
    "\n",
    "Welcome to the first lab of Data Science Foundations! This lab is meant to help you familiarize yourself with Jupyter Notebook, review Python and `numpy`, and `Pandas`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Jupyter Tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Documentation\n",
    "\n",
    "To output the documentation for a function, use the `help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "help(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Magic Commands\n",
    "\n",
    "In Data Science Foundations, we will be using common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names. Below are some of the libraries that you may encounter throughout the course, along with their respective aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyboard Shortcuts\n",
    "\n",
    "Even if you are familiar with Jupyter, we strongly encourage you to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to **Help --> Keyboard Shortcuts** in the menu above.\n",
    "\n",
    "Here are a few that we like:\n",
    "1. `Ctrl` + `Return` (or `Cmd` + `Return` on Mac): *Evaluate the current cell*\n",
    "1. `Shift` + `Return`: *Evaluate the current cell and move to the next*\n",
    "1. `ESC` : *command mode* (may need to press before using any of the commands below)\n",
    "1. `a` : *create a cell above*\n",
    "1. `b` : *create a cell below*\n",
    "1. `dd` : *delete a cell*\n",
    "1. `z` : *undo the last cell operation*\n",
    "1. `m` : *convert a cell to markdown*\n",
    "1. `y` : *convert a cell to code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Prerequisites\n",
    "\n",
    "It's time to answer some review questions. Each question has a response cell directly below it. Most response cells are followed by a test cell that runs automated tests to check your work. Please don't delete questions, response cells, or test cells. You won't get credit for your work if you do.\n",
    "\n",
    "If you have extra content in a response cell, such as an example call to a function you're implementing, that's fine. Also, feel free to add cells between the question cells and test cells (or the next cell, for questions without test cases). Any extra cells you add will be considered part of your submission. Finally, when you finish an assignment, make sure to \"restart and run all cells\" to ensure everything works properly.\n",
    "\n",
    "Note that for labs, ontime submissions that pass all the test cases will receive full credit. However for homeworks, test cells don't always confirm that your response is correct. They are meant to give you some useful feedback, but it's your responsibility to ensure your response answers the question correctly. There may be other tests that we run when scoring your notebooks. We **strongly recommend** that you check your solutions yourself rather than just relying on the test cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "Python is the main programming language we'll use in the course. We expect that you've taken Python programming courses, or an equivalent class, so we will not be covering general Python syntax. If any of the following exercises are challenging (or if you would like to refresh your Python knowledge), please review one or more of the following materials.\n",
    "\n",
    "- **[Python Tutorial](https://docs.python.org/3.8/tutorial/)**: Introduction to Python from the creators of Python.\n",
    "- **[Composing Programs Chapter 1](http://composingprograms.com/pages/11-getting-started.html)**: This is more of a introduction to programming with Python.\n",
    "- **[Advanced Crash Course](http://cs231n.github.io/python-numpy-tutorial/)**: A fast crash course which assumes some programming background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "NumPy is the numerical computing module. Here's a quick recap of NumPy. For more review, read the following materials.\n",
    "\n",
    "- **[NumPy Quick Start Tutorial](https://numpy.org/doc/stable/user/quickstart.html)**\n",
    "- **[DS100 NumPy Review](http://ds100.org/fa17/assets/notebooks/numpy/Numpy_Review.html)**\n",
    "- **[Stanford CS231n NumPy Tutorial](http://cs231n.github.io/python-numpy-tutorial/#numpy)**\n",
    "- **[The Data 8 Textbook Chapter on NumPy](https://www.inferentialthinking.com/chapters/05/1/Arrays)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "The core of NumPy is the array. Like Python lists, arrays store data; however, they store data in a more efficient manner. In many cases, this allows for faster computation and data manipulation.\n",
    "\n",
    "Use `np.array` to create an array. It takes a sequence, such as a list or range.\n",
    "\n",
    "Below, create an array `arr` containing the values 1, 2, 3, 4, and 5 (in that order).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert type(arr) is np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to values in the array, we can access attributes such as shape and data type. A full list of attributes can be found [here](https://docs.scipy.org/doc/numpy-1.15.0/reference/arrays.ndarray.html#array-attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays, unlike Python lists, cannot store items of different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A regular Python list can store items of different data types\n",
    "[1, '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Arrays will convert everything to the same data type\n",
    "np.array([1, '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Another example of array type conversion\n",
    "np.array([5, 8.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are also useful in performing *vectorized operations*. Given two or more arrays of equal length, arithmetic will perform element-wise computations across the arrays.\n",
    "\n",
    "For example, observe the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Python list addition will concatenate the two lists\n",
    "[1, 2, 3] + [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NumPy array addition will add them element-wise\n",
    "np.array([1, 2, 3]) + np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a\n",
    "\n",
    "Write a function `summation` that evaluates the following summation for $n \\geq 1$:\n",
    "\n",
    "$$\\sum_{i=1}^{n} i^3 + 3 i^2$$\n",
    "\n",
    "**Note**: You should not use `for` loops in your solution. Check the [NumPy documentation](https://numpy.org/doc/1.19/reference/index.html). If you're stuck, try a search engine! Searching the web for examples of how to use modules is very common in data science.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def summation(n):\n",
    "    \"\"\"Compute the summation i^3 + 3 * i^2 for 1 <= i <= n.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert summation(1) == 4\n",
    "assert summation(2) == 24\n",
    "assert summation(100) == 26517550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2b\n",
    "\n",
    "Write a function `elementwise_array_sum` that computes the square of each value in `list_1`, the cube of each value in `list_2`, then returns a list containing the element-wise sum of these results. Assume that `list_1` and `list_2` have the same number of elements, do not use for loops.\n",
    "\n",
    "The input parameters will both be **python lists**, so you may need to convert the lists into arrays before performing your operations. The output should be a **numpy array.**\n",
    "\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def elementwise_array_sum(list_1, list_2):\n",
    "    \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2.\n",
    "\n",
    "    Assume list_1 and list_2 have the same length.\n",
    "\n",
    "    Return a NumPy array.\n",
    "    \"\"\"\n",
    "    assert len(list_1) == len(list_2), \"both args must have the same number of elements\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert elementwise_array_sum([1], [1]) == np.array([2])\n",
    "assert elementwise_array_sum([-1], [1]) == np.array([2])\n",
    "assert elementwise_array_sum([1], [-1]) == np.array([0])\n",
    "assert (elementwise_array_sum([1, 2, 3], [1, 2, 3]) == np.array([ 2, 12, 36])).all()\n",
    "assert (elementwise_array_sum([1, 5, 2], [3, 6, 6]) == np.array([ 28, 241, 220])).all()\n",
    "assert type(elementwise_array_sum([], [])) is np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have been told that Python is slow, but array arithmetic is carried out very fast, even for large arrays. Below is an implementation of the above code that does not use NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def elementwise_list_sum(list_1, list_2):\n",
    "    \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2.\n",
    "\n",
    "    Assume list_1 and list_2 have the same length.\n",
    "    \"\"\"\n",
    "\n",
    "    return [x ** 2 + y ** 3 for x, y in zip(list_1, list_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ten numbers, `elementwise_list_sum` and `elementwise_array_sum` both take a similar amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_list_1 = list(range(10))\n",
    "sample_array_1 = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "elementwise_list_sum(sample_list_1, sample_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "elementwise_array_sum(sample_array_1, sample_array_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time difference seems negligible for a list/array of size 10; depending on your setup, you may even observe that `elementwise_list_sum` executes faster than `elementwise_array_sum`! However, we will commonly be working with much larger datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_list_2 = list(range(100000))\n",
    "sample_array_2 = np.arange(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "elementwise_list_sum(sample_list_2, sample_list_2)\n",
    "; # The semicolon hides the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "elementwise_array_sum(sample_array_2, sample_array_2)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the larger dataset, we see that using NumPy results in code that executes over 50 times faster! Throughout this course (and in the real world), you will find that writing efficient code will be important; arrays and vectorized operations are the most common way of making Python programs run quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2d\n",
    "\n",
    "Given the array `random_arr`, assign `valid_values` to an array containing all values $x$ such that $2x^4 > 1$.\n",
    "\n",
    "**Note**: You should not use `for` loops in your solution. Instead, look at `numpy`'s documentation on [Boolean Indexing](https://numpy.org/devdocs/reference/arrays.indexing.html).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random_arr = np.random.rand(60)\n",
    "valid_values = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(valid_values) == 10\n",
    "assert np.allclose(valid_values, [0.95071431, 0.86617615, 0.96990985, 0.94888554, 0.96563203, 0.9093204 , 0.96958463, 0.93949894, 0.89482735, 0.92187424])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Pandas Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Pandas](https://pandas.pydata.org/) is one of the most widely used Python libraries in data science. In this lab, you will review commonly used data wrangling operations/tools in Pandas. We aim to give you familiarity with:\n",
    "\n",
    "* Creating DataFrames\n",
    "* Slicing DataFrames (i.e. selecting rows and columns)\n",
    "* Filtering data (using boolean arrays and groupby.filter)\n",
    "* Aggregating (using groupby.agg)\n",
    "\n",
    "In this lab you are going to use several pandas methods. Reminder from lecture that you may press `shift+tab` on method parameters to see the documentation for that method. For example, if you were using the `drop` method in pandas, you could press shift+tab to see what `drop` is expecting.\n",
    "\n",
    "This lab expects that you have watched the pandas lectures. If you have not, this lab will probably take a very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The Pandas interface is notoriously confusing for beginners, and the documentation is not consistently great. Throughout the semester, you will have to search through Pandas documentation and experiment, but remember it is part of the learning experience and will help shape you as a data scientist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames & Basic Manipulations\n",
    "\n",
    "Recall that a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe) is a table in which each column has a specific data type; there is an index over the columns (typically string labels) and an index over the rows (typically ordinal numbers).\n",
    "\n",
    "Usually you'll create DataFrames by using a function like `pd.read_csv`. However, in this section, we'll discuss how to create them from scratch.\n",
    "\n",
    "The [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for the pandas `DataFrame` class provides several constructors for the DataFrame class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax 1:** You can create a DataFrame by specifying the columns and values using a dictionary as shown below.\n",
    "\n",
    "The keys of the dictionary are the column names, and the values of the dictionary are lists containing the row entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info = pd.DataFrame(\n",
    "    data = {'fruit': ['apple', 'orange', 'banana', 'raspberry'],\n",
    "          'color': ['red', 'orange', 'yellow', 'pink'],\n",
    "          'price': [1.0, 0.75, 0.35, 0.05]\n",
    "          })\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax 2:** You can also define a DataFrame by specifying the rows as shown below.\n",
    "\n",
    "Each row corresponds to a distinct tuple, and the columns are specified separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info2 = pd.DataFrame(\n",
    "    [(\"red\", \"apple\", 1.0), (\"orange\", \"orange\", 0.75), (\"yellow\", \"banana\", 0.35),\n",
    "     (\"pink\", \"raspberry\", 0.05)],\n",
    "    columns = [\"color\", \"fruit\", \"price\"])\n",
    "fruit_info2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtain the dimensions of a DataFrame by using the shape attribute `DataFrame.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert the entire DataFrame into a two-dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other constructors but we do not discuss them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVIEW: Selecting Rows and Columns in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen in lecture and discussion, there are two verbose operators in Python for selecting rows: `loc` and `iloc`. Let's review them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: `loc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of the two verbose operators is `loc`, which takes two arguments. The first is one or more row **labels**, the second is one or more column **labels**.\n",
    "\n",
    "The desired rows or columns can be provided individually, in slice notation, or as a list. Some examples are given below.\n",
    "\n",
    "Note that **slicing in `loc` is inclusive** on the provided labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#get rows 0 through 2 and columns fruit through price\n",
    "fruit_info.loc[0:2, 'fruit':'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 through 2 and columns fruit and price.\n",
    "# Note the difference in notation and result from the previous example.\n",
    "fruit_info.loc[0:2, ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and columns fruit and price.\n",
    "fruit_info.loc[[0, 2], ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit\n",
    "fruit_info.loc[[0, 2], ['fruit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we request a single column but don't enclose it in a list, the return type of the `loc` operator is a `Series` rather than a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit, returning the result as a Series\n",
    "fruit_info.loc[[0, 2], 'fruit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide only one argument to `loc`, it uses the provided argument to select rows, and returns all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info.loc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` is very similar to `loc` except that its arguments are row numbers and column numbers, rather than row labels and labels names. A usueful mnemonic is that the `i` stands for \"integer\".\n",
    "\n",
    "In addition, **slicing for `iloc` is exclusive** on the provided integer indices. Some examples are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 through 3 (exclusive) and columns 0 through 2 (exclusive)\n",
    "fruit_info.iloc[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 through 3 (exclusive) and columns 0 and 2.\n",
    "fruit_info.iloc[0:3, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and columns 0 and 2.\n",
    "fruit_info.iloc[[0, 2], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in these loc and iloc examples above, the row **label** and row **number** were always the same.\n",
    "\n",
    "Let's see an example where they are different. If we sort our fruits by price, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info_sorted = fruit_info.sort_values(\"price\")\n",
    "fruit_info_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the row number 0 now has index 3, row number 1 now has index 2, etc. These indices are the arbitrary numerical index generated when we created the DataFrame. For example, banana was originally in row 2, and so it has row label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we request the rows in positions 0 and 2 using `iloc`, we're indexing using the row NUMBERS, not labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info_sorted.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, similar to with `loc`, the second argument to `iloc` is optional. That is, if you provide only one argument to `iloc`, it treats the argument you provide as a set of desired row numbers, not column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info.iloc[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 3: `[]` Notation for Accessing Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also supports a bare `[]` operator. It's similar to `loc` in that it lets you access rows and columns by their name.\n",
    "\n",
    "However, unlike `loc`, which takes row names and also optionally column names, `[]` is more flexible. If you provde it only row names, it'll give you rows (same behavior as `loc`), and if you provide it with only column names, it'll give you columns (whereas `loc` will crash).\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we're providing a list of fruits as single argument to []\n",
    "fruit_info[[\"fruit\", \"color\", \"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that slicing notation is not supported for columns if you use `[]` notation. Use `loc` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment and this code crashes\n",
    "#fruit_info[\"fruit\":\"price\"]\n",
    "\n",
    "# uncomment and this works fine\n",
    "#fruit_info.loc[:, \"fruit\":\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[]` and `loc` are quite similar. For example, the following two pieces of code are functionally equivalent for selecting the fruit and price columns.\n",
    "\n",
    "1. `fruit_info[[\"fruit\", \"price\"]]`\n",
    "2. `fruit_info.loc[:, [\"fruit\", \"price\"]]`.\n",
    "\n",
    "Because it yields more concise code, you'll find that our code and your code both tend to feature `[]`. However, there are some subtle pitfalls of using `[]`. If you're ever having performance issues, weird behavior, or you see a `SettingWithCopyWarning` in pandas, switch from `[]` to `loc` and this may help.\n",
    "\n",
    "To avoid getting too bogged down in indexing syntax, we'll avoid a more thorough discussion of `[]` and `loc`. We may return to this at a later point in the course.\n",
    "\n",
    "For more on `[]` vs `loc`, you may optionally try reading:\n",
    "1. https://stackoverflow.com/questions/48409128/what-is-the-difference-between-using-loc-and-using-just-square-brackets-to-filte\n",
    "2. https://stackoverflow.com/questions/38886080/python-pandas-series-why-use-loc/65875826#65875826\n",
    "3. https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas/53954986#53954986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've reviewed basic indexing, let's discuss how we can modify dataframes. We'll do this via a series of exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "For a DataFrame `d`, you can add a column with `d['new column name'] = ...` and assign a list or array of values to the column. Add a column of integers containing 1, 2, 3, and 4 called `rank` to the `fruit_info` table which expresses your personal preference about the taste ordering for each fruit (1 is tastiest; 4 is least tasty).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert fruit_info[\"rank\"].dtype == np.dtype('int64')\n",
    "assert sorted(fruit_info[\"rank\"].dropna()) == [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Use the `.drop()` method to [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) the `rank` column you created. Make sure to use the `axis` parameter correctly. Note that `drop` does not change a table, but instead returns a new table with fewer columns or rows unless you set the optional `inplace` parameter.\n",
    "\n",
    "*Hint*: Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) to see how you can drop multiple columns of a Pandas DataFrame at once using a list of column names.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fruit_info_original = ...\n",
    "fruit_info_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert fruit_info_original.shape == (4, 3)\n",
    "assert fruit_info.shape == (4, 4)\n",
    "assert (fruit_info_original.columns == np.array(['fruit', 'color', 'price'], dtype='object')).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Use the `.rename()` method to [rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) the columns of `fruit_info_original` so they begin with capital letters. Set this new DataFrame to `fruit_info_caps`. For an example of how to use rename, see the linked documentation above.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert (fruit_info_caps.columns == np.array(['Fruit', 'Color', 'Price'], dtype='object')).all()\n",
    "assert (fruit_info.columns == np.array(['fruit', 'color', 'price', 'rank'], dtype='object')).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Babynames Dataset\n",
    "For the new few questions of this lab, let's move on to a real world dataset. We'll be using the babynames dataset from Lecture 1. The babynames dataset contains a record of the given names of babies born in the United States each year.\n",
    "\n",
    "First let's run the following cells to build the DataFrame `baby_names`.\n",
    "The cells below download the data from the web and extract the data into a DataFrame. There should be a total of 6215834 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_and_cache` Helper\n",
    "\n",
    "The following function downloads and caches data in the `data/` directory and returns the `Path` to the downloaded file. The cell below the function describes how it works. You are not expected to understand this code, but you may find it useful as a reference as a practitioner of data science after the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "\n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded\n",
    "\n",
    "    return: The pathlib.Path to the file.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        import time\n",
    "        created = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using cached version downloaded at\", created)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a `Path` object represents the filesystem paths to files (and other resources). The `pathlib` module is effective for writing code that works on different operating systems and filesystems.\n",
    "\n",
    "To check if a file exists at a path, use `.exists()`. To create a directory for a path, use `.mkdir()`. To remove a file that might be a [symbolic link](https://en.wikipedia.org/wiki/Symbolic_link), use `.unlink()`.\n",
    "\n",
    "This function creates a path to a directory that will contain data files. It ensures that the directory exists (which is required to write files in that directory), then proceeds to download the file based on its URL.\n",
    "\n",
    "The benefit of this function is that not only can you force when you want a new file to be downloaded using the `force` parameter, but in cases when you don't need the file to be re-downloaded, you can use the cached version and save download time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use `fetch_and_cache` to download the `namesbystate.zip` zip file, which is a compressed directory of CSV files.\n",
    "\n",
    "**This might take a little while! Consider stretching.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds the final full `baby_names` DataFrame. It first builds one DataFrame per state, because that's how the data are stored in the zip file. Here is documentation for [pd.concat](https://pandas.pydata.org/pandas-docs/version/1.2/reference/api/pandas.concat.html) if you want to know more about its functionality. As before, you are not expected to understand this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zf = zipfile.ZipFile(namesbystate_path, 'r')\n",
    "\n",
    "column_labels = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "def load_dataframe_from_zip(zf, f):\n",
    "    with zf.open(f) as fh:\n",
    "        return pd.read_csv(fh, header=None, names=column_labels)\n",
    "\n",
    "states = [\n",
    "    load_dataframe_from_zip(zf, f)\n",
    "    for f in sorted(zf.filelist, key=lambda x:x.filename)\n",
    "    if f.filename.endswith('.TXT')\n",
    "]\n",
    "\n",
    "baby_names = states[0]\n",
    "for state_df in states[1:]:\n",
    "    baby_names = pd.concat([baby_names, state_df])\n",
    "baby_names = baby_names.reset_index().iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baby_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use `.loc` to select `Name` and `Year` **in that order** from the `baby_names` table.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_and_year = ...\n",
    "name_and_year[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert name_and_year.shape == (6215834, 2)\n",
    "assert name_and_year.loc[0, \"Name\"] == 'Mary'\n",
    "assert name_and_year.loc[0, \"Year\"] == 1910"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Filtering with boolean arrays\n",
    "\n",
    "Filtering is the process of removing unwanted material.  In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, for culling out fishy outliers, or for analyzing subgroups of your data set.  Example usage looks like `df[df['column name'] < 5]`.\n",
    "\n",
    "For your reference, some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning\n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    "&gt;=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we construct the DataFrame containing only names registered in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ca = baby_names[baby_names['State'] == 'CA']\n",
    "ca.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Using a boolean array, select the names in Year 2000 (from `baby_names`) that have larger than 3000 counts. Keep all columns from the original `baby_names` DataFrame.\n",
    "\n",
    "Note: Note that compound expressions have to be grouped with parentheses. That is, any time you use `p & q` to filter the DataFrame, make sure to use `df[(df[p]) & (df[q])]` or `df.loc[(df[p]) & (df[q])]`.\n",
    "\n",
    "You may use either `[]` or `loc`. Both will achieve the same result. For more on `[]` vs. `loc` see the stack overflow links from the intro portion of this lab.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = ...\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(result) == 11\n",
    "assert result[\"Count\"].sum() == 39000\n",
    "assert result[\"Count\"].iloc[0] == 4342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "Let's now turn to using groupby from lecture 4.\n",
    "\n",
    "**Note:** This [slide](https://docs.google.com/presentation/d/1FC-cs5MTGSkDzI_7R_ZENgwoHQ4aVamxFOpJuWT0fo0/edit#slide=id.g477ed0f02e_0_390) provides a visual picture of how `groupby.agg` works if you'd like a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**: Let's start by reading in the election dataset from the pandas lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, we can groupby a specific column, e.g. \"Party\". It turns out that using some syntax we didn't cover in lecture, we can print out the subframes that result. This isn't something you'll do for any practical purpose. However, it may help you get an understanding of what groupby is actually doing.\n",
    "\n",
    "An example is given below for elections since 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "for n, g in elections.query(\"Year >= 1980\").groupby(\"Party\"):\n",
    "    print(f\"Name: {n}\") # by the way this is an \"f string\", a relatively new and great feature of Python\n",
    "    display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that once we've formed groups, we can aggregate each sub-dataframe (a.k.a. group) into a single row using an aggregation function. For example, if we use `.agg(np.mean)` on the groups above, we get back a single DataFrame where each group has been replaced by a single row. In each column for that aggregate row, the value that appears is the average of all values in that group.\n",
    "\n",
    "For columns which are non-numeric, e.g. \"Result\", the column is dropped because we cannot compute the mean of the Result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently we can use one of the shorthand aggregation functions, e.g. `.mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index of the dataframe returned by an `groupby.agg` call is no longer a set of numeric indices from 0 to N-1. Instead, we see that the index for the example above is now the `Party`. If we want to restore our DataFrame so that `Party` is a column rather than the index, we can use `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** You should NEVER NEVER solve problems like the one above using loops or list comprehensions. This is slow and also misses the entire point of this part of DS100.\n",
    "\n",
    "Before we continue, we'll print out the election dataset again for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6a\n",
    "Using `groupby.agg` or one of the shorthand methods (`groupby.min`, `groupby.first`, etc.), create a Series `best_result_percentage_only` that returns a Series showing the entire best result for every party, sorted in decreasing order. Your Series should include only parties which have earned at least 10% of the vote in some election. Your result should look like this:\n",
    "\n",
    "<code>\n",
    "Party\n",
    "Democratic               61.344703\n",
    "Republican               60.907806\n",
    "Democratic-Republican    57.210122\n",
    "National Union           54.951512\n",
    "Whig                     53.051213\n",
    "Liberal Republican       44.071406\n",
    "National Republican      43.796073\n",
    "Northern Democratic      29.522311\n",
    "Progressive              27.457433\n",
    "American                 21.554001\n",
    "Independent              18.956298\n",
    "Southern Democratic      18.138998\n",
    "American Independent     13.571218\n",
    "Constitutional Union     12.639283\n",
    "Free Soil                10.138474\n",
    "Name: %, dtype: float64\n",
    "</code>\n",
    "<br/>\n",
    "\n",
    "A list of named `groupby.agg` shorthand methods is [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#aggregation) (you'll have to scroll down about one page).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "# put your code above this line\n",
    "best_result_percentage_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(best_result_percentage_only) == 15\n",
    "assert best_result_percentage_only[\"Independent\"].sum() == 18.95629754\n",
    "assert best_result_percentage_only.iloc[0] == 61.34470329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame contains a number of parties which have never had a successful presidential run. For example, the 2020 elections included candiates from the Libertarian and Green parties, neither of which have elected a president."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "elections.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were conducting an analysis trying to focus our attention on parties that had elected a president.\n",
    "\n",
    "The most natural approach is to use `groupby.filter`. This is an incredibly powerful but subtle tool for filtering data.\n",
    "\n",
    "As a reminder of how filter works, see [this slide](https://docs.google.com/presentation/d/1FC-cs5MTGSkDzI_7R_ZENgwoHQ4aVamxFOpJuWT0fo0/edit#slide=id.g5ff184b7f5_0_507).\n",
    "The code below accomplishes the task at hand. It does this by creating a function that returns True if and only if a sub-dataframe (a.k.a. group) contains at least one winner. This function in turn uses the [Pandas function \"any\"](https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "def at_least_one_candidate_in_the_frame_has_won(frame):\n",
    "    \"\"\"Returns df with rows only kept for parties that have\n",
    "    won at least one election\n",
    "    \"\"\"\n",
    "    return (frame[\"Result\"] == 'win').any()\n",
    "\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(at_least_one_candidate_in_the_frame_has_won)\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately we could have used a `lambda` function instead of explicitly defining a named function using `def`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell (alternative)\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(lambda x : (x[\"Result\"] == \"win\").any())\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your exercise, you'll do a less restrictive filtering of the elections data.\n",
    "\n",
    "**Exercise**: Using `filter`, create a DataFrame `major_party_results_since_1988` that includes all election results starting in 1988, but only show a row if the Party it belongs to has earned at least 1% of the popular vote in ANY election since 1988.\n",
    "\n",
    "For example, in 1988, you should not include the `New Alliance` candidate, since this party has not earned 1% of the vote since 1988. However, you should include the `Libertarian` candidate from 1988 despite only having 0.47 percent of the vote in 1988, because in 2016 and 2020, the Libertarian candidates Gary Johnson and Jo Jorgensen exceeded 1% of the vote.\n",
    "\n",
    "For example, the first three rows of the table you generate should look like:\n",
    "\n",
    "|     |   Year | Candidate         | Party       |   Popular vote | Result   |         % |\n",
    "|----:|-------:|:------------------|:------------|---------------:|:---------|----------:|\n",
    "| 135 |   1988 | George H. W. Bush | Republican  |       48886597 | win      | 53.5188   |\n",
    "| 137 |   1988 | Michael Dukakis   | Democratic  |       41809074 | loss     | 45.7707   |\n",
    "| 138 |   1988 | Ron Paul          | Libertarian |         431750 | loss     |  0.47266  |\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "major_party_results_since_1988.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert major_party_results_since_1988.shape == (40, 6)\n",
    "assert major_party_results_since_1988[\"%\"].min() == 0.098088334\n",
    "assert major_party_results_since_1988[\"Candidate\"].iloc[0] == 'George H. W. Bush'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides special purpose functions for working with specific common data types such as strings and dates. For example, the code below provides the length of every Candidate's name from our elections dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections[\"Candidate\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Using `.str.split`. Create a new DataFrame called `elections_with_first_name` with a new column `First Name` that is equal to the Candidate's first name.\n",
    "\n",
    "See the Pandas `str` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) for documentation on using `str.split`.\n",
    "\n",
    "Hint: Use `[0]` somewhere in your code.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elections_with_first_name = elections.copy()\n",
    "# your code here\n",
    "...\n",
    "# end your code\n",
    "elections_with_first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert elections_with_first_name.shape == (182, 7)\n",
    "assert elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"First Name\"] == 'Andrew'\n",
    "assert elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"First Name\"] == 'Jo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a table with the frequency of all names from 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "baby_names_2020 = (\n",
    "    baby_names.query('Year == 2020')\n",
    "              .groupby(\"Name\")\n",
    "              .sum()[[\"Count\"]]\n",
    "              .reset_index()\n",
    ")\n",
    "baby_names_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Using the `pd.merge` function, see the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html), combine the `baby_names_2020` table with the `elections_with_first_name` table you created earlier to form `presidential_candidates_and_name_popularity`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "presidential_candidates_and_name_popularity = ...\n",
    "presidential_candidates_and_name_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert presidential_candidates_and_name_popularity.shape == (153, 9)\n",
    "assert presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"Name\"] == 'Andrew'\n",
    "assert presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"Count\"] == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
